{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bcee5ba",
      "metadata": {
        "id": "9bcee5ba",
        "outputId": "285a0f72-f886-4661-b9a0-106c8a04e8c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in Tkinter callback\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\anaconda3\\Lib\\tkinter\\__init__.py\", line 592, in get\n",
            "    return self._tk.getint(value)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "_tkinter.TclError: expected integer but got \"\"\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
            "    return self.func(*args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\Temp\\ipykernel_20892\\1389806722.py\", line 22, in save_response2\n",
            "    response2_text = response2.get()\n",
            "                     ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\anaconda3\\Lib\\tkinter\\__init__.py\", line 594, in get\n",
            "    return int(self._tk.getdouble(value))\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "_tkinter.TclError: expected floating-point number but got \"\"\n",
            "Exception in Tkinter callback\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\anaconda3\\Lib\\tkinter\\__init__.py\", line 592, in get\n",
            "    return self._tk.getint(value)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "_tkinter.TclError: expected integer but got \"\"\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
            "    return self.func(*args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\Temp\\ipykernel_20892\\1389806722.py\", line 28, in save_response4\n",
            "    response4_text = response4.get()\n",
            "                     ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\anaconda3\\Lib\\tkinter\\__init__.py\", line 594, in get\n",
            "    return int(self._tk.getdouble(value))\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "_tkinter.TclError: expected floating-point number but got \"\"\n",
            "Exception in Tkinter callback\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
            "    return self.func(*args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\Temp\\ipykernel_20892\\1389806722.py\", line 151, in execute_function\n",
            "    API_RT.append(float(Impurity_DF[Impurity_DF['Area']==a].Retention_Time))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\thurman.falk\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py\", line 230, in wrapper\n",
            "    raise TypeError(f\"cannot convert the series to {converter}\")\n",
            "TypeError: cannot convert the series to <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "#Import the libraries necessary to run this program\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "from tkinter import *\n",
        "from PIL import Image, ImageTk\n",
        "\n",
        "def open_file():\n",
        "    file_path = filedialog.askopenfilename()\n",
        "    if file_path:\n",
        "        file_label.config(text=\"Selected File: \" + file_path)\n",
        "        file_path_var.set(file_path)\n",
        "\n",
        "def save_response1(root, *args):\n",
        "    response1_text = response1.get()\n",
        "\n",
        "def save_response2(root, *args):\n",
        "    response2_text = response2.get()\n",
        "\n",
        "def save_response3(root, *args):\n",
        "    response3_text = response3.get()\n",
        "\n",
        "def save_response4(root, *args):\n",
        "    response4_text = response4.get()\n",
        "\n",
        "def save_response5(root, *args):\n",
        "    response5_text = response5.get()\n",
        "\n",
        "def save_response6(root, *args):\n",
        "    response6_text = response6.get()\n",
        "\n",
        "def save_response8(root, *args):\n",
        "    response8_text = response8.get()\n",
        "\n",
        "def toggle_input_field():\n",
        "    if c_v1.get() == 1:  # Checkbox is checked\n",
        "        response_label5.grid(row=11, column=0, padx=10, pady=5, sticky=\"w\")\n",
        "        response5_entry.grid(row=12, column=0, padx=10, pady=5, sticky=\"w\")\n",
        "    else:\n",
        "        response_label5.grid_forget()  # Hide the label field when checkbox is unchecked\n",
        "        response5_entry.grid_forget()  # Hide the input field when checkbox is unchecked\n",
        "\n",
        "def toggle_input_field2():\n",
        "    if c_v2.get() == 1:  # Checkbox is checked\n",
        "        response_label6.grid(row=14, column=0, padx=10, pady=5, sticky=\"w\")\n",
        "        response6_entry.grid(row=15, column=0, padx=10, pady=5, sticky=\"w\")\n",
        "    else:\n",
        "        response_label6.grid_forget()  # Hide the label field when checkbox is unchecked\n",
        "        response6_entry.grid_forget()  # Hide the input field when checkbox is unchecked\n",
        "\n",
        "def toggle_input_field3():\n",
        "    if c_v3.get() == 1:  # Checkbox is checked\n",
        "        response_label8.grid(row=19, column=0, padx=10, pady=5, sticky=\"w\")\n",
        "        response8_entry.grid(row=20, column=0, padx=10, pady=5, sticky=\"w\")\n",
        "    else:\n",
        "        response_label8.grid_forget()  # Hide the label field when checkbox is unchecked\n",
        "        response8_entry.grid_forget()  # Hide the input field when checkbox is unchecked\n",
        "\n",
        "def update_line():\n",
        "    selected_option.get() in ['a', 'all']\n",
        "    selected_option.get() in ['b', 'all']\n",
        "    selected_option.get() == 'all'\n",
        "\n",
        "def execute_function():\n",
        "    loadpath = file_path_var.get()\n",
        "    Blank_Name = response1.get()\n",
        "    Blank_Num = int(response2.get())\n",
        "    STD_Name = response3.get()\n",
        "    STD_Num = int(response4.get())\n",
        "    Sens_Inj = c_v1.get()\n",
        "    SensSTD = response5.get()\n",
        "    Chk_Inj = c_v2.get()\n",
        "    STD2 = response6.get()\n",
        "    Reps = selected_option.get()\n",
        "    Excip_Inj = c_v3.get()\n",
        "    Excip = response8.get()\n",
        "    path = save_path_var.get()\n",
        "\n",
        "    # Perform all RRT Table calculations and export table after hitting execute button\n",
        "\n",
        "    # Import the file and save it as a Data Frame\n",
        "    DF= pd.read_csv(loadpath, sep=\"\\t\")\n",
        "\n",
        "    #Create a new list for Injection Ids\n",
        "    Inj_Ids=[]\n",
        "    Inj_Ids=DF['Injection Id'].unique()\n",
        "\n",
        "    #Create a Data Frame for Impurity Analysis\n",
        "    Impurity_DF=pd.DataFrame()\n",
        "    Impurity_DF['Sample_Name']=DF['SampleName']\n",
        "    Impurity_DF['Injection_Ids']=DF['Injection Id']\n",
        "    Impurity_DF['Retention_Time']=DF['Retention Time']\n",
        "    Impurity_DF['Area']=DF['Area']\n",
        "\n",
        "    # Save lists with the number of blank injections and the Injection Ids\n",
        "    Blank_Injs=Impurity_DF[Impurity_DF['Sample_Name']==Blank_Name].Injection_Ids.unique().tolist()\n",
        "    Num_Blank_Injs=len(Impurity_DF[Impurity_DF['Sample_Name']==Blank_Name].Injection_Ids.unique().tolist())\n",
        "\n",
        "    # Save the Injection ID of the analysis standard\n",
        "    Anal_Blank=Blank_Injs[Blank_Num-1]\n",
        "\n",
        "    # Remove the Injection ID of the analysis standard from the list of Standard Injection Ids\n",
        "    Blank_Injs.remove(Anal_Blank)\n",
        "\n",
        "    # Storing the Standard index values of the Impurity Data Frame to drop\n",
        "    Blank_Index=[]\n",
        "    for i in Blank_Injs:\n",
        "      Blank_Index.append(Impurity_DF[Impurity_DF['Injection_Ids']==i].index.values)\n",
        "\n",
        "    #Removing the unwanted standard injections from the Impurity Data Frame\n",
        "    for i in Blank_Index:\n",
        "      Impurity_DF=Impurity_DF.drop(i)\n",
        "\n",
        "    # Create a new Data Frame for blanks peaks\n",
        "    Blank_DF=pd.DataFrame()\n",
        "    # List all peak retention times and areas to add to DF\n",
        "    Blank_DF['Area']=Impurity_DF[Impurity_DF['Injection_Ids']==Anal_Blank].Area.reset_index(drop=True)\n",
        "    Blank_DF['Blank_RT']=Impurity_DF[Impurity_DF['Injection_Ids']==Anal_Blank].Retention_Time.reset_index(drop=True)\n",
        "\n",
        "    # Remove the blank from the Impurity Data Frame since it has been saved in the Blank Data Frame\n",
        "    Impurity_DF.drop(Impurity_DF[Impurity_DF['Sample_Name']==Blank_Name].index, inplace=True)\n",
        "\n",
        "    # Drop rows in the impurity data frame that don't have a peak, i.e. total impurities rows generated from Empower\n",
        "    Impurity_DF.dropna(inplace= True)\n",
        "\n",
        "    # Making sure the index of the Impurity Data Frame starts from 0\n",
        "    Impurity_DF.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Identifying the injection sequence and creating a list of injection IDs and Sample Names\n",
        "    Seq=Impurity_DF.groupby('Injection_Ids')['Sample_Name'].unique().to_frame()\n",
        "    # Remove the blank from the Sequence Data Frame since\n",
        "    Seq.drop(Seq[Seq['Sample_Name']==Blank_Name].index, inplace=True)\n",
        "\n",
        "    # Create a list of the areas of the API peaks\n",
        "    API_Peak_Areas=Impurity_DF.groupby('Injection_Ids')['Area'].max().to_list()\n",
        "\n",
        "    # Identify the any injections in the API Peak Area lists that don't have a peak area\n",
        "    blank_values = np.isnan(API_Peak_Areas)\n",
        "    # Remove the blank values\n",
        "    API_Peak_Areas = np.delete(API_Peak_Areas, blank_values)\n",
        "\n",
        "    # Create a list for the retention time of the API peaks\n",
        "    API_RT=[]\n",
        "\n",
        "    # Loop through the Impurity Data Frame to find the API retention times and Injection IDs and add to the lists\n",
        "    for a in API_Peak_Areas:\n",
        "      API_RT.append(float(Impurity_DF[Impurity_DF['Area']==a].Retention_Time))\n",
        "\n",
        "    # Create a new Table for only the API peaks that includes Injecction ID, Retention Time, and Area\n",
        "    Seq['API_RT']=API_RT\n",
        "    Seq['API_Peak_Areas']=(API_Peak_Areas)\n",
        "    Seq.sort_values('Sample_Name', inplace=True)\n",
        "\n",
        "    # Save lists with the number of Standard injections and the Injection Ids\n",
        "    STD1_Injs=Impurity_DF[Impurity_DF['Sample_Name']==STD_Name].Injection_Ids.unique().tolist()\n",
        "    Num_STD1_Injs=len(Impurity_DF[Impurity_DF['Sample_Name']==STD_Name].Injection_Ids.unique().tolist())\n",
        "\n",
        "    # Save the Injection ID of the analysis standard\n",
        "    Anal_STD=STD1_Injs[STD_Num-1]\n",
        "\n",
        "    # Remove the Injection ID of the analysis standard from the list of Standard Injection Ids\n",
        "    STD1_Injs.remove(Anal_STD)\n",
        "\n",
        "    # Storing the Standard index values of the Impurity Data Frame to drop\n",
        "    Standard_Index=[]\n",
        "    for i in STD1_Injs:\n",
        "      Standard_Index.append(Impurity_DF[Impurity_DF['Injection_Ids']==i].index.values)\n",
        "\n",
        "    #Removing the unwanted standard injections from the Impurity Data Frame\n",
        "    for i in Standard_Index:\n",
        "      Impurity_DF=Impurity_DF.drop(i)\n",
        "\n",
        "    # If Sensitivity and Check STD are part of sequence, drop based on their name\n",
        "    if Sens_Inj==1:\n",
        "      # Dropping SensSTD from the Impurity Data Frame\n",
        "      Impurity_DF.drop(Impurity_DF[Impurity_DF['Sample_Name']==SensSTD].index, inplace=True)\n",
        "\n",
        "    if Chk_Inj==1:\n",
        "      # Dropping Chk STD from Impurity Data Frame\n",
        "      Impurity_DF.drop(Impurity_DF[Impurity_DF['Sample_Name']==STD2].index, inplace=True)\n",
        "\n",
        "    # Making sure the index of the Impurity Data Frame starts from 0\n",
        "    Impurity_DF.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Select which sample replicates to include in the RRT table\n",
        "    SNL=Impurity_DF.Sample_Name.to_list()\n",
        "    if Reps=='a':\n",
        "      for i in np.arange(len(SNL)):\n",
        "        if 'b' in SNL[i]:\n",
        "          Impurity_DF.drop([i], axis=0, inplace=True)\n",
        "    elif Reps=='b':\n",
        "      for i in np.arange(len(SNL)):\n",
        "        if 'a' in SNL[i]:\n",
        "          Impurity_DF.drop([i], axis=0, inplace=True)\n",
        "\n",
        "    # Create a list of the areas of the API peaks\n",
        "    API_Peak_Areas=Impurity_DF.groupby('Injection_Ids')['Area'].max().to_list()\n",
        "\n",
        "    # Create a list for the rention time of the API peaks\n",
        "    API_RT=[]\n",
        "\n",
        "    # Create a list for the Injection ID of the API peaks\n",
        "    A_Id=[]\n",
        "\n",
        "    # Create a list for the Samples Names of each Injection ID\n",
        "    A_Sampnames=[]\n",
        "\n",
        "    # Loop through the Impurity Data Frame to find the API rention times and Injection IDs and add to the lists\n",
        "    for a in API_Peak_Areas:\n",
        "      A_Sampnames.append(Impurity_DF[Impurity_DF['Area']==a].Sample_Name.values)\n",
        "      API_RT.append(float(Impurity_DF[Impurity_DF['Area']==a].Retention_Time))\n",
        "      A_Id.append(int(Impurity_DF[Impurity_DF['Area']==a].Injection_Ids))\n",
        "\n",
        "    # Create a new Table for only the API peaks that includes Injecction ID, Retention Time, and Area\n",
        "    API_Table=pd.DataFrame()\n",
        "    API_Table['A_Id']=(A_Id)\n",
        "    API_Table['Sample_Name']=A_Sampnames\n",
        "    API_Table['API_RT']=API_RT\n",
        "    API_Table['API_Peak_Areas']=(API_Peak_Areas)\n",
        "\n",
        "    # Make a list of every retention time for each injection ID\n",
        "    RT_DF=Impurity_DF.groupby('Injection_Ids')['Retention_Time'].unique().to_frame()\n",
        "\n",
        "    # If excipient or polymer blank was part of injection sequence.\n",
        "    if Excip_Inj==1:\n",
        "      # Add the excipient retention time and peak area to the Blank Data Frame\n",
        "      Blank_DF.loc[Blank_DF.shape[0]] = [int(Impurity_DF[Impurity_DF['Sample_Name']==Excip].Area), float(Impurity_DF[Impurity_DF['Sample_Name']==Excip].Retention_Time)]\n",
        "      # Dropping Excipient from the Impurity Data Frame\n",
        "      Impurity_DF.drop(Impurity_DF[Impurity_DF['Sample_Name']==Excip].index, inplace=True)\n",
        "\n",
        "    # Calculate RRT in the Blank Table by dividing by the Standard Retention Time\n",
        "    Blank_DF['Blank_RRT']=round(Blank_DF['Blank_RT']/API_RT[0],2)\n",
        "\n",
        "    # Drop peaks by RRT if blank peak is also present in excipient blank to avoid double subtraction\n",
        "    Blank_DF = Blank_DF.drop_duplicates(subset=['Blank_RRT'], keep='first')\n",
        "\n",
        "    # Make a list to save calulated RRTs\n",
        "    RRT = []\n",
        "\n",
        "    # For each retention time calculate the RRT and save it to the list\n",
        "    for i in range(len(API_Table.A_Id)):\n",
        "      Cur_ID = int(API_Table.A_Id[i])\n",
        "      Cur_RT = API_Table.API_RT[i]\n",
        "      if Cur_ID in RT_DF.index:\n",
        "        for j in range(len(RT_DF.loc[Cur_ID])):\n",
        "          Inj = RT_DF.loc[Cur_ID]\n",
        "          RRT.append(np.round((Inj[j] / Cur_RT),3))\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "    # Defining a function to flatten a two dimensional list into a single list\n",
        "    def flatten_array(array_of_arrays):\n",
        "        return [item for sublist in array_of_arrays for item in sublist]\n",
        "\n",
        "    # Saving a list of RRTs in 1D that was flattened from 2D.\n",
        "    flat_RRT = flatten_array(RRT)\n",
        "\n",
        "    # Add the list of RRTs as a new column to the Impurity Data Frame\n",
        "    Impurity_DF['RRT']=flat_RRT\n",
        "\n",
        "    # Making sure the index of the Impurity Data Frame starts from 0\n",
        "    Impurity_DF.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Round the RRT values to 2 places\n",
        "    Impurity_DF['RRT']=round(Impurity_DF['RRT'],2)\n",
        "\n",
        "    # Remove rows that don't have a peak from the blank Data Frame\n",
        "    Blank_DF.dropna(inplace= True)\n",
        "    # Reset the Blank Data Frame index\n",
        "    Blank_DF.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Looping through all blank peaks and subtracting them from peaks in the Impurity Data Frame if the RRTs match\n",
        "    Loop_pos=0\n",
        "    Area_Blank_Sub=Impurity_DF.Area.reset_index(drop=True)\n",
        "\n",
        "    for i in Blank_DF['Blank_RRT']:\n",
        "      if (Impurity_DF.RRT==(i)).any():\n",
        "        for j in np.arange(len(Area_Blank_Sub)):\n",
        "          if Impurity_DF.RRT.reset_index(drop=True)[j]==i:\n",
        "            Area_Blank_Sub[j]=(Area_Blank_Sub[j]-Blank_DF.Area[Loop_pos])\n",
        "            if Area_Blank_Sub[j]<0:                                           # If subtracting the blank peak results in a negative number, set the area equal to 0\n",
        "              Area_Blank_Sub[j]=np.nan\n",
        "            else:\n",
        "              continue\n",
        "          else:\n",
        "            continue\n",
        "        Loop_pos+=1\n",
        "      else:\n",
        "        Loop_pos+=1\n",
        "        continue\n",
        "\n",
        "    # Resetting the Area Column to be the Blank Subtracted Adjusted Area\n",
        "    Impurity_DF['Area']=Area_Blank_Sub\n",
        "\n",
        "    # For every injection calculate the cumulative area and make sure its greater than zero, drop injections with no peaks from dataframe\n",
        "    for i in range(len(API_Table.A_Id)):\n",
        "      Cur_ID = int(API_Table.A_Id[i])\n",
        "      Cum_Area = Impurity_DF.groupby('Injection_Ids')['Area'].sum()\n",
        "      Cur_Cum_Area= int(Cum_Area[Cur_ID])\n",
        "      if Cur_Cum_Area == 0:\n",
        "            Impurity_DF.drop(Impurity_DF[Impurity_DF['Injection_Ids']==Cur_ID].index, inplace=True)\n",
        "            API_Table.drop(API_Table[API_Table['A_Id']==Cur_ID].index, inplace=True)\n",
        "    # Making sure the index of the Data Frames start from 0\n",
        "    Impurity_DF.reset_index(drop=True, inplace=True)\n",
        "    API_Table.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Make a list to store calculated percent areas\n",
        "    Per_Area = []\n",
        "\n",
        "    # For every peak calculate the percent area by dividing by the cumulative area of that Injection ID\n",
        "    for i in range(len(API_Table.A_Id)):\n",
        "      Cur_ID = int(API_Table.A_Id[i])\n",
        "      Cum_Area = Impurity_DF.groupby('Injection_Ids')['Area'].sum()\n",
        "      Cur_Cum_Area= int(Cum_Area[Cur_ID])\n",
        "      if Cur_ID in Impurity_DF.Injection_Ids.to_list():\n",
        "        for j in range(len(Impurity_DF[Impurity_DF['Injection_Ids']==Cur_ID].Area)):\n",
        "          Areas = Impurity_DF[Impurity_DF['Injection_Ids']==Cur_ID].Area.to_list()\n",
        "          Per_Area.append(Areas[j]*100/Cur_Cum_Area)\n",
        "          next\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "    # Add a Percent Area column to the Impurity DF\n",
        "    Impurity_DF['Percent_Area']=Per_Area\n",
        "\n",
        "    # Add a new column to the Impurity DF that calculates if the percent area is above 0.05%\n",
        "    Impurity_DF['Above_LOQ']=Impurity_DF.Percent_Area>=0.05\n",
        "\n",
        "    # Add a new column to the Impurity DF that includes on peak areas above the 0.05% LOQ threshold\n",
        "    Impurity_DF['Area_Above_LOQ']=Impurity_DF.Above_LOQ*Impurity_DF.Area\n",
        "\n",
        "    # Recalculate percent areas of only peaks that are above LOQ\n",
        "    # Make a list to store calculated percent areas\n",
        "    Per_Area = []\n",
        "\n",
        "    # For every peak calculate the percent area by dividing by the cumulative area of Peaks>LOQ of that Injection ID\n",
        "    for i in range(len(API_Table.A_Id)):\n",
        "      Cur_ID = int(API_Table.A_Id[i])\n",
        "      Cum_Area = Impurity_DF.groupby('Injection_Ids')['Area_Above_LOQ'].sum()\n",
        "      Cur_Cum__Area= int(Cum_Area[Cur_ID])\n",
        "      if Cur_ID in Impurity_DF.Injection_Ids.to_list():\n",
        "        for j in range(len(Impurity_DF[Impurity_DF['Injection_Ids']==Cur_ID].Area)):\n",
        "          Areas = Impurity_DF[Impurity_DF['Injection_Ids']==Cur_ID].Area.to_list()\n",
        "          Per_Area.append(Areas[j]*100/Cur_Cum__Area)\n",
        "          next\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "    # Add a new column to the Impurity Data Frame that is the Reportable Percent Areas\n",
        "    Impurity_DF['Percent_Area']=Per_Area\n",
        "\n",
        "    # Remove RRT 1.0 from the Impurity Data Frame\n",
        "    Impurity_DF.drop(Impurity_DF[Impurity_DF['RRT']==1.00].index, inplace=True)\n",
        "\n",
        "    # Construct an RRRT table of percent areas by RRT according to sample name with a pivot table\n",
        "    pivottable = pd.pivot_table(Impurity_DF, index='RRT', columns=['Sample_Name'], values='Percent_Area', aggfunc=lambda x: x) # Using lambda to pass multiple values when there are two peaks with same RRT in one sample\n",
        "\n",
        "    # Create a function to combine sparse RRT rows if the RRT is +/- 0.01 and the rows can be considered the same peak\n",
        "    def RRT_Consolidator(DF):\n",
        "      DF_Shape=DF.shape\n",
        "      DF_Cols=DF_Shape[1]\n",
        "      DF_Rows=DF_Shape[0]\n",
        "      for row in DF.index:\n",
        "        if DF[DF.index==row].isnull().sum().sum()>=0.5*DF_Cols:\n",
        "          if (DF.index==(row-0.01)).any():\n",
        "            if DF[DF.index==row].isnull().sum().sum()>DF[DF.index==(row-0.01)].isnull().sum().sum():\n",
        "              #Check if cells are empty and move to more populated row.\n",
        "              Loop_pos=0\n",
        "              count=0\n",
        "              row_array=DF[DF.index==row].values[0]\n",
        "              for val in row_array:\n",
        "                if np.isnan(val):\n",
        "                  Loop_pos+=1\n",
        "                  continue\n",
        "                else:\n",
        "                  #Move cell to new row as long as the new cell is empty.\n",
        "                  if np.isnan(DF[DF.index==(row-0.01)].values[0,Loop_pos]):\n",
        "                    new_row=DF[DF.index==(row-0.01)].values.tolist()[0]\n",
        "                    new_row[Loop_pos]=val # Add the value in the correct column to the new row\n",
        "                    DF.loc[DF.index==(row-0.01)]=new_row\n",
        "                    row_array[Loop_pos]=np.nan # Remove the value from the correct column in the old row\n",
        "                    DF[DF.index==row]=row_array # Save the updated row to the data frame\n",
        "                    DF=DF.sort_index()\n",
        "                    Loop_pos+=1\n",
        "                    count+=1\n",
        "                    if DF_Cols==DF[DF.index==row].isnull().sum().sum():\n",
        "                      #if all the items in the row have been moved, delete the row.\n",
        "                      DF=DF.drop(index=row)\n",
        "                    else:\n",
        "                      continue\n",
        "                  else:\n",
        "                    Loop_pos+=1\n",
        "                    continue\n",
        "\n",
        "            elif DF[DF.index==row].isnull().sum().sum()==DF[DF.index==(row-0.01)].isnull().sum().sum():\n",
        "              #Check if cells are empty and move to more lower RRT row.\n",
        "              Loop_pos=0\n",
        "              count=0\n",
        "              row_array=DF[DF.index==row].values[0]\n",
        "              for val in row_array:\n",
        "                if np.isnan(val):\n",
        "                  Loop_pos+=1\n",
        "                  continue\n",
        "                else:\n",
        "                  #Move cell to new row as long as the new cell is empty.\n",
        "                  if np.isnan(DF[DF.index==(row-0.01)].values[0,Loop_pos]):\n",
        "                    new_row=DF[DF.index==(row-0.01)].values.tolist()[0]\n",
        "                    new_row[Loop_pos]=val # Add the value in the correct column to the new row\n",
        "                    DF.loc[DF.index==(row-0.01)]=new_row\n",
        "                    row_array[Loop_pos]=np.nan # Remove the value from the correct column in the old row\n",
        "                    DF[DF.index==row]=row_array # Save the updated row to the data frame\n",
        "                    DF=DF.sort_index()\n",
        "                    Loop_pos+=1\n",
        "                    count+=1\n",
        "                    if DF_Cols==DF[DF.index==row].isnull().sum().sum():\n",
        "                      #if all the items in the row have been moved, delete the row.\n",
        "                      DF=DF.drop(index=row)\n",
        "            else:\n",
        "                continue\n",
        "          elif (DF.index==(row+0.01)).any():\n",
        "            if DF[DF.index==row].isnull().sum().sum()>DF[DF.index==(row+0.01)].isnull().sum().sum():\n",
        "              #Check if cells are empty and move to more populated row.\n",
        "              Loop_pos=0\n",
        "              count=0\n",
        "              row_array=DF[DF.index==row].values[0]\n",
        "              for val in row_array:\n",
        "                if np.isnan(val):\n",
        "                  Loop_pos+=1\n",
        "                  continue\n",
        "                else:\n",
        "                  #Move cell to new row as long as the new cell is empty.\n",
        "                  if np.isnan(DF[DF.index==(row+0.01)].values[0,Loop_pos]):\n",
        "                    new_row=DF[DF.index==(row+0.01)].values.tolist()[0]\n",
        "                    new_row[Loop_pos]=val # Add the value in the correct column to the new row\n",
        "                    DF.loc[DF.index==(row+0.01)]=new_row\n",
        "                    row_array[Loop_pos]=np.nan # Remove the value from the correct column in the old row\n",
        "                    DF[DF.index==row]=row_array # Save the updated row to the data frame\n",
        "                    DF=DF.sort_index()\n",
        "                    Loop_pos+=1\n",
        "                    count+=1\n",
        "                    if DF_Cols==DF[DF.index==row].isnull().sum().sum():\n",
        "                      #if all the items in the row have been moved, delete the row.\n",
        "                      DF=DF.drop(index=row)\n",
        "                    else:\n",
        "                      continue\n",
        "                  else:\n",
        "                    Loop_pos+=1\n",
        "                    continue\n",
        "            else:\n",
        "              continue\n",
        "          else:\n",
        "            continue\n",
        "        else:\n",
        "          continue\n",
        "      return DF\n",
        "\n",
        "    # Run the consolidator function and save the table result\n",
        "    pivottable=RRT_Consolidator(pivottable)\n",
        "\n",
        "    # Function to replace values less than 0.05 with \"<0.05%\"\n",
        "    def replace_values(val):\n",
        "        new_values = []\n",
        "        if type(val) == np.ndarray:\n",
        "            for v in val:\n",
        "                if float(v) < 0.05:\n",
        "                    new_values.append(\"<0.05%\")\n",
        "                else:\n",
        "                   new_values.append(v)\n",
        "        else:\n",
        "          if val < 0.05:\n",
        "              new_values=\"<0.05%\"\n",
        "          else:\n",
        "              new_values=val\n",
        "\n",
        "        return new_values\n",
        "\n",
        "    # Apply the function to the entire DataFrame\n",
        "    pivottable = pivottable.applymap(replace_values)\n",
        "\n",
        "    # Define a function to convert values to numeric (ignores non-numeric strings)\n",
        "    def convert_to_numeric(value):\n",
        "        try:\n",
        "            return pd.to_numeric(value)\n",
        "        except:\n",
        "            return np.nan\n",
        "\n",
        "    # Apply the conversion function to the entire DataFrame\n",
        "    numeric_df = pivottable.applymap(convert_to_numeric)\n",
        "\n",
        "    # Define a custom function to calculate the sum of elements in a cell\n",
        "    def custom_sum(cell_value):\n",
        "        if isinstance(cell_value, np.ndarray):\n",
        "            return sum(cell_value)\n",
        "        else:\n",
        "            return cell_value\n",
        "\n",
        "    # Apply the custom_sum function with a loop to the specified column and add to a list\n",
        "    cumulative_sum=[]\n",
        "    for col in numeric_df.columns:\n",
        "      cumulative_sum.append(round(numeric_df[col].apply(custom_sum).sum(),2))\n",
        "\n",
        "    # Adding a Total Impurities row at the bottom of the pivot table\n",
        "    pivottable.loc['Total Impurities']=cumulative_sum\n",
        "\n",
        "    # Function to round numeric values in data frame\n",
        "    def round_values(val):\n",
        "        new_values = []\n",
        "        if type(val) == list:\n",
        "            for v in val:\n",
        "              if type(v)== np.float64:\n",
        "                new_values.append(round(v,2))\n",
        "              else:\n",
        "                new_values.append(v)\n",
        "            return new_values\n",
        "        elif type(val) == str:\n",
        "            return val\n",
        "        elif type(val) == np.float64:\n",
        "            round_value=round(val,2)\n",
        "            return round_value\n",
        "        elif type(val) == float:\n",
        "            round_value=round(val,2)\n",
        "            return round_value\n",
        "        else:\n",
        "          return val\n",
        "\n",
        "    # Apply the function to the entire DataFrame\n",
        "    pivottable = pivottable.applymap(round_values)\n",
        "\n",
        "    with pd.ExcelWriter(path) as engine:\n",
        "        pivottable.to_excel(excel_writer=engine, sheet_name='RRT_Table', index=True)\n",
        "        Seq.to_excel(excel_writer=engine, sheet_name='API_Table')\n",
        "\n",
        "    # Update the status label to indicate successful execution\n",
        "    status_label.config(text=\"App ran successfully!\")\n",
        "\n",
        "def browse_folder():\n",
        "    folder_path = filedialog.askdirectory()\n",
        "    if folder_path:\n",
        "        selected_folder_label.config(text=f\"Selected Folder: {folder_path}\")\n",
        "        global selected_folder_path\n",
        "        selected_folder_path = folder_path\n",
        "\n",
        "def save_file():\n",
        "    if selected_folder_path:\n",
        "        save_path = filedialog.asksaveasfilename(defaultextension=\".xlsx\")\n",
        "        if save_path:\n",
        "            saved_label.config(text=f\"Filepath saved to: {save_path}\")\n",
        "            save_path_var.set(save_path)\n",
        "\n",
        "# Create the main window\n",
        "root = tk.Tk()\n",
        "root.title(\"RRT Table Generator\")\n",
        "\n",
        "root.geometry(\"750x900\")  # Size of the window\n",
        "root.geometry('+%d+%d'%(350,10)) #place GUI at x=350, y=10\n",
        "\n",
        "#logo\n",
        "#resizing the displayed image while keeping its ratio\n",
        "def resize_image(img):\n",
        "    width, height = int(img.size[0]), int(img.size[1])\n",
        "    height = int(150/width*height)\n",
        "    width = 150\n",
        "    img = img.resize((width, height))\n",
        "    return img\n",
        "\n",
        "logo = Image.open('RRT Icon.png')\n",
        "logo = resize_image(logo)\n",
        "logo = ImageTk.PhotoImage(logo)\n",
        "logo_label = tk.Label(image=logo)\n",
        "logo_label.image = logo\n",
        "logo_label.grid(column=2, row=0)\n",
        "\n",
        "# Create variables to store the responses\n",
        "file_path_var = tk.StringVar()\n",
        "\n",
        "response1 = tk.StringVar()\n",
        "\n",
        "response2 = tk.IntVar(value=0)\n",
        "\n",
        "response3 = tk.StringVar()\n",
        "\n",
        "response4 = tk.IntVar(value=0)\n",
        "\n",
        "response5 = tk.StringVar()\n",
        "\n",
        "response6 = tk.StringVar()\n",
        "\n",
        "response8 = tk.StringVar()\n",
        "\n",
        "c_v1=IntVar()\n",
        "\n",
        "c_v2=IntVar()\n",
        "\n",
        "c_v3=IntVar()\n",
        "\n",
        "selected_filepath = \"\"\n",
        "save_path_var = tk.StringVar()\n",
        "\n",
        "# Create a radio button variable\n",
        "selected_option = tk.StringVar()\n",
        "\n",
        "# Initialize the selected_option variable\n",
        "selected_option.set(None)\n",
        "\n",
        "# Create widgets\n",
        "open_button = tk.Button(root, text=\"Open File\", command=open_file)\n",
        "file_label = tk.Label(root, text=\"Selected File: None\")\n",
        "\n",
        "# Questions and Response\n",
        "response_label1 = tk.Label(root, text=\"Please input how the blank is named, must be exact. e.g. Blank\")\n",
        "response1_entry = tk.Entry(root, textvariable=response1)\n",
        "# Bind the response variable to a callback\n",
        "response1.trace_add('write', save_response1)\n",
        "\n",
        "# Questions and Response\n",
        "response_label2 = tk.Label(root, text=\"Please input which blank to use, input number e.g. 3\")\n",
        "response2_entry = tk.Entry(root, textvariable=response2)\n",
        "# Bind the response variable to a callback\n",
        "response2.trace_add('write', save_response2)\n",
        "\n",
        "# Questions and Response\n",
        "response_label3 = tk.Label(root, text=\"Please input how the standard you want to use for impurity analysis is named, must be exact. e.g. STD1\")\n",
        "response3_entry = tk.Entry(root, textvariable=response3)\n",
        "# Bind the response variable to a callback\n",
        "response3.trace_add('write', save_response3)\n",
        "\n",
        "# Questions and Response\n",
        "response_label4 = tk.Label(root, text=\"Please input which standard injection to use, input number e.g. 1 or 5\")\n",
        "response4_entry = tk.Entry(root, textvariable=response4)\n",
        "# Bind the response variable to a callback\n",
        "response4.trace_add('write', save_response4)\n",
        "\n",
        "# Questions and Response\n",
        "response_label5 = tk.Label(root, text=\"Please input how the Sensitivity Standard is named, must be exact. e.g. SensSTD\")\n",
        "response5_entry = tk.Entry(root, textvariable=response5)\n",
        "# Bind the response variable to a callback\n",
        "response5.trace_add('write', save_response5)\n",
        "\n",
        "# Questions and Response\n",
        "response_label6 = tk.Label(root, text=\"Please input how the Check Standard is named, must be exact. e.g. STD2\")\n",
        "response6_entry = tk.Entry(root, textvariable=response6)\n",
        "# Bind the response variable to a callback\n",
        "response6.trace_add('write', save_response6)\n",
        "\n",
        "check = tk.Checkbutton(root,text='Sample set includes Sensitivity Standard',variable=c_v1, onvalue=1, offvalue=0,\n",
        "\tcommand=toggle_input_field)\n",
        "\n",
        "check2 = tk.Checkbutton(root,text='Sample set includes Check Standard',variable=c_v2,\n",
        "\tonvalue=1,offvalue=0,command=toggle_input_field2)\n",
        "\n",
        "response_label7 = tk.Label(root, text=\"What sample replicates to include in the RRT Table? (a, b, all)\")\n",
        "\n",
        "# Create radio buttons\n",
        "radio_button_a = tk.Radiobutton(root, text=\"Replicate A\", variable=selected_option, value='a', command=update_line)\n",
        "radio_button_b = tk.Radiobutton(root, text=\"Replicate B\", variable=selected_option, value='b', command=update_line)\n",
        "radio_button_all = tk.Radiobutton(root, text=\"All Replicates\", variable=selected_option, value='all', command=update_line)\n",
        "\n",
        "check3 = tk.Checkbutton(root,text='Sample set includes a polymer or excipient blank', variable=c_v3,\n",
        "\tonvalue=1,offvalue=0,command=toggle_input_field3)\n",
        "\n",
        "# Questions and Response\n",
        "response_label8 = tk.Label(root, text=\"Please input how the polymer or excipient blank is named, must be exact. e.g. SSF\")\n",
        "response8_entry = tk.Entry(root, textvariable=response8)\n",
        "# Bind the response variable to a callback\n",
        "response8.trace_add('write', save_response8)\n",
        "\n",
        "# Create the execute button to complete the program\n",
        "execute_button = tk.Button(root, text=\"Execute\", command=execute_function)\n",
        "\n",
        "# Browse folders and save the file\n",
        "browse_button = tk.Button(root, text=\"Browse Folder\", command=browse_folder)\n",
        "\n",
        "selected_folder_label = tk.Label(root, text=\"Select Save Folder: \")\n",
        "\n",
        "save_button = tk.Button(root, text=\"Save Filename\", command=save_file)\n",
        "\n",
        "saved_label = tk.Label(root, text=\"\")\n",
        "\n",
        "status_label = tk.Label(root, text=\"\")\n",
        "\n",
        "# Place widgets using grid layout\n",
        "open_button.grid(row=1, column=0, padx=10, pady=3, sticky=\"w\")\n",
        "file_label.grid(row=1, column=0, padx=10, pady=3, columnspan=3, sticky=\"e\")\n",
        "\n",
        "response_label1.grid(row=2, column=0, padx=10, pady=3, columnspan=2, sticky=\"w\")\n",
        "response1_entry.grid(row=3, column=0, padx=10, pady=3, columnspan=3, sticky=\"w\")\n",
        "\n",
        "response_label2.grid(row=4, column=0, padx=10, pady=3, columnspan=2, sticky=\"w\")\n",
        "response2_entry.grid(row=5, column=0, padx=10, pady=3, columnspan=3, sticky=\"w\")\n",
        "\n",
        "response_label3.grid(row=6, column=0, padx=10, pady=3, columnspan=2, sticky=\"w\")\n",
        "response3_entry.grid(row=7, column=0, padx=10, pady=3, columnspan=3, sticky=\"w\")\n",
        "\n",
        "response_label4.grid(row=8, column=0, padx=10, pady=3, columnspan=2, sticky=\"w\")\n",
        "response4_entry.grid(row=9, column=0, padx=10, pady=3, columnspan=3, sticky=\"w\")\n",
        "\n",
        "check.grid(row=10,column=0, padx=10, pady=10, sticky=\"w\")\n",
        "\n",
        "response_label5.grid(row=11, column=0, padx=10, pady=3, columnspan=2, sticky=\"w\")\n",
        "response5_entry.grid(row=12, column=0, padx=10, pady=3, columnspan=3, sticky=\"w\")\n",
        "response_label5.grid_forget()  # Hide the label field when checkbox is unchecked\n",
        "response5_entry.grid_forget()  # Hide the input field when checkbox is unchecked\n",
        "\n",
        "check2.grid(row=13,column=0, padx=10, pady=10, sticky=\"w\")\n",
        "\n",
        "response_label6.grid(row=14, column=0, padx=10, pady=3, columnspan=2, sticky=\"w\")\n",
        "response6_entry.grid(row=15, column=0, padx=10, pady=3, columnspan=3, sticky=\"w\")\n",
        "response_label6.grid_forget()  # Hide the label field when checkbox is unchecked\n",
        "response6_entry.grid_forget()  # Hide the input field when checkbox is unchecked\n",
        "\n",
        "response_label7.grid(row=16, column=0, padx=10, pady=10, columnspan=2, sticky=\"w\")\n",
        "\n",
        "radio_button_a.grid(row=17, column=0, columnspan=1, padx=10, pady=3, sticky=\"e\")\n",
        "radio_button_b.grid(row=17, column=1, columnspan=1, padx=10, pady=3, sticky=\"w\")\n",
        "radio_button_all.grid(row=17, column=2, columnspan=1, padx=10, pady=3, sticky=\"w\")\n",
        "\n",
        "check3.grid(row=18,column=0, padx=10, pady=10, sticky=\"w\")\n",
        "\n",
        "response_label8.grid(row=19, column=0, padx=10, pady=3, columnspan=2, sticky=\"w\")\n",
        "response8_entry.grid(row=20, column=0, padx=10, pady=3, columnspan=3, sticky=\"w\")\n",
        "response_label8.grid_forget()  # Hide the label field when checkbox is unchecked\n",
        "response8_entry.grid_forget()  # Hide the input field when checkbox is unchecked\n",
        "\n",
        "browse_button.grid(row=21, column=0, columnspan=1, padx=10, pady=3, sticky=\"w\")\n",
        "selected_folder_label.grid(row=22, column=0, columnspan=3, padx=3, pady=10, sticky=\"w\")\n",
        "\n",
        "save_button.grid(row=23, column=0, columnspan=1, padx=10, pady=3, sticky=\"w\")\n",
        "saved_label.grid(row=24, column=0, columnspan=3, padx=10, pady=3, sticky=\"w\")\n",
        "\n",
        "execute_button.grid(row=25, column=0, columnspan=1, padx=10, pady=3, sticky=\"w\")\n",
        "\n",
        "status_label.grid(row=25, column=1, columnspan=1, padx=10, pady=3, sticky=\"w\")\n",
        "\n",
        "# Tkinter event loop\n",
        "root.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca728007",
      "metadata": {
        "id": "ca728007"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}